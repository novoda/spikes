{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis for the #general Slack channel",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
    "source": [
        "<a href=\"https://colab.research.google.com/github/novoda/spikes/blob/master/sentiment-analysis/Sentiment_Analysis_for_the_general_Slack_channel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITnSt9jzEqk-"
      },
      "source": [
        "**Sentiment Analysis for Slack channels**\n",
        "What we will be doing:\n",
        "  1. Retrieve the `channel_id` for `#general`\n",
        "  2. Retrieve the channel history from 31/05/2020\n",
        "  3. Filter out non-user messages\n",
        "  4. Run sentiment analysis on the list of retrieved messages. Values `<0` are for negative sentiment, values `>0` for positive sentiment.\n",
        "  5. Some data processing to group by date and split the data in two columns, one for `number of possitive messages` and one for `number of negative messages`\n",
        "  6. Plot the data!\n",
        "\n",
        "---------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQhVdYsIIQbK"
      },
      "source": [
        "First of all, let's install `slack_sdk` package, which is what we'll be using to make calls to the Slack API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JScAB9KBCS3C"
      },
      "source": [
        "!pip install slack_sdk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgfNL6nEIerT"
      },
      "source": [
        "Now, let's import the dependencies for our project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnD9-lcfAmYN"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from slack_sdk import WebClient\n",
        "from slack_sdk.errors import SlackApiError\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI2BQllSI2Pc"
      },
      "source": [
        "\n",
        "\n",
        "Instantiate a logger for the possible error messages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqlaJltKI0cV"
      },
      "source": [
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC7omnYsJBv_"
      },
      "source": [
        "-------------------------------\n",
        "**Data Retrieval**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EQhgsvmdkFI"
      },
      "source": [
        "\n",
        "We will instantiate `client` for making calls to the Slack API\n",
        "`token` is the token for your Slack App or Bot.\n",
        "\n",
        "When creating your App or Bot there is something to consider. `OAuth` `channels:history` and `channels:read` scopes needs to be added to either `Bot Token Scopes` or `User Token` scopes. This is under your app management settings on `OAuth & Permissions`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH_Xk6IyCaLF"
      },
      "source": [
        "client = WebClient(token=\"YOUR-TOKEN-HERE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejCOwdG3OJYH"
      },
      "source": [
        "Now we need to retrieve the `channel_id` which identifies the channel on which we are willing to perform the sentiment analysis.\n",
        "1. Request `conversations_list`\n",
        "2. Loop throught the list of channels until we find a match by `name`\n",
        "3. Get the `id` for the channel that matched the `name`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1vTBCNkCdty"
      },
      "source": [
        "channel_id = None\n",
        "target = 'general'\n",
        "try:\n",
        "    result = client.conversations_list()\n",
        "    for response in result:\n",
        "        for channel in result[\"channels\"]:\n",
        "            if channel[\"name\"] == target:\n",
        "                channel_id = channel[\"id\"]\n",
        "                break\n",
        "except SlackApiError as e:\n",
        "    logger.error(\"Error: {}\".format(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7h8eL0UaLvS"
      },
      "source": [
        "Once we have the `channel_id` for the channel we are going to be working on, it's time to retrieve the channel history.\n",
        "\n",
        "We retrieve messages from 31 May 2020, but there is a limitation on the `conversations_history` method, there is a limit of `1000` messages for call, so we need to perform multiple calls for different \n",
        "\n",
        "There is a constraint on the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGrdjnQaCsHG"
      },
      "source": [
        "conversation_history = []\n",
        "\n",
        "try:\n",
        "    # Call the conversations.history method using the WebClient\n",
        "    # conversations.history returns the first 100 messages by default, with a maximum of 1000\n",
        "    pending_messages = True\n",
        "    start_date = 1590883200 # 31 May 2020\n",
        "    conversation_history = []\n",
        "    while pending_messages:\n",
        "        result = client.conversations_history(channel=channel_id, inclusive=False, oldest=start_date, count=1000)[\"messages\"]\n",
        "        conversation_history = conversation_history + result\n",
        "        if len(result) == 0:\n",
        "            pending_messages = False\n",
        "        else:\n",
        "            start_date = result[0].get('ts')\n",
        "            pending_messages = True\n",
        "except SlackApiError as e:\n",
        "    logger.error(\"Error: {}\".format(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-O5YjbGb0RD"
      },
      "source": [
        "Next thing we do is to filter out everything which is not a message (like notifications) and messages that are not from users (there is no `client_message_id` associated to it)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGc1iD9Tb1_4"
      },
      "source": [
        "filtered_history = list(\n",
        "    filter(\n",
        "        lambda x: x.get('type') == 'message' and x.get('client_msg_id') is not None,\n",
        "        conversation_history\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2AWhz5ac-Ed"
      },
      "source": [
        "\n",
        "And a matrix is created with `date` and `text` of the message as columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh_pAvaGc-0F"
      },
      "source": [
        "conversation_history_messages_by_date = list(\n",
        "    map(\n",
        "        lambda x: [datetime.fromtimestamp(float(x.get('ts'))).strftime(\"%Y%m%d\"), x.get('text')],\n",
        "        filtered_history\n",
        "    )\n",
        ")\n",
        "\n",
        "conversation_history_messages_by_date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bThQ1dnAdQnX"
      },
      "source": [
        "---------------------------------\n",
        "**Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12CWU9WmdmZr"
      },
      "source": [
        "The first thing we are going do to towards this approach is to download the `VADER` lexicon. An ordered series of words mapped to the sentiment they transmit. `VADER` stands for Valence Aware Dictionary and sEntiment Reasoner.\n",
        "\n",
        "This is going to be used by [Neural Language Tool Kit](https://www.nltk.org/), `nltk`, in order to be able to analyse sentiments of messages. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93EuMjtxDKMN"
      },
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q58iIMlueXjv"
      },
      "source": [
        "Once the dictionary is downloaded, we instantiate our `SentimentIntensityAnalyzer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pajQM-JODNO6"
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBLVNPAFeiIT"
      },
      "source": [
        "And we analyze sentiments. We map the `conversation_history_messages_by_date` soo the `message` column is transformed to `sentiment`.\n",
        "\n",
        "A value under 0 is considered a negative sentiment\n",
        "A value over 0 is considered a positive sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAte-2mdehzf"
      },
      "source": [
        "conversation_history_sentiments_by_date = list(\n",
        "    map(\n",
        "        lambda x: [x[0], analyzer.polarity_scores(x[1]).get('compound')],\n",
        "        conversation_history_messages_by_date\n",
        "    ),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf46TrrZe1YP"
      },
      "source": [
        "Finally, for data representation, we are grouping the data by `date` and creating two separate columns. \n",
        "1. `negative` containing the number of negative messages on a date\n",
        "2. `positive` containing the number of positive messages on a date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQIRA6fBfD73"
      },
      "source": [
        "net_sentiment_by_date = pd.DataFrame(conversation_history_sentiments_by_date, columns=[\"date\", \"sentiment\"])\n",
        "net_sentiment_by_date = net_sentiment_by_date.groupby('date')['sentiment'].agg(\n",
        "    positive=lambda x: x.gt(0).sum(),\n",
        "    negative=lambda x: x.lt(0).sum()\n",
        ")\n",
        "\n",
        "net_sentiment_by_date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xIyYtwXfT3H"
      },
      "source": [
        "And we plot our data. We are done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGl12SN8DbQp"
      },
      "source": [
        "net_sentiment_by_date[['positive', 'negative']].plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

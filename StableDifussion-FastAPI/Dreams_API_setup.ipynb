{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-sTN3TBchrx"
      },
      "source": [
        "The first thing we have to do is checking if we have support for a GPU.\n",
        "\n",
        "It's required to enable GPU hardware accelerator over `Edit > Notebook Settings`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_klMPbFIclHU"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy4SgJRJdY8X"
      },
      "source": [
        "## Next bunch of code is to set up `Stable Diffussion`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZPdH77SdrQh"
      },
      "source": [
        "1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SlkoU1tduS2"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers==0.2.4\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install \"ipywidgets>=7,<8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqB-M5xxd4A4"
      },
      "source": [
        "2. Enable external Colab widgets\n",
        "\n",
        "This allows to connect to hugging face, which will be used to download stable difussion models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgCPBz6bd9hh"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4TTRM-veJAT"
      },
      "source": [
        "3. Connect to Hugging Face\n",
        "\n",
        "For this step you will have to create an account for `Hugging Face` if you haven't already; and accept their terms and conditions. The widget have a link to the website where you would be doing that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxjShDZoeT92"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhmpbsVseeyQ"
      },
      "source": [
        "4. Initialize `Stable Diffussion Pipeline` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stgtqe9seh5w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5neUYbx8el4I"
      },
      "source": [
        "5. Move pipeline to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBk7eSl5e18O"
      },
      "outputs": [],
      "source": [
        "pipe = pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "502XhoyFe8Wk"
      },
      "source": [
        "6. Run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkyI4kUxfBzv"
      },
      "outputs": [],
      "source": [
        "from torch import autocast\n",
        "import io\n",
        "\n",
        "\n",
        "def dream(prompt: str):\n",
        "  with autocast(\"cuda\"):\n",
        "    image = pipe(prompt)[\"sample\"][0]  \n",
        "\n",
        "  byteIO = io.BytesIO()\n",
        "  image.save(byteIO, format='PNG')\n",
        "  return byteIO.getvalue()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teo6PNWfiD-7"
      },
      "source": [
        "----------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vKxY3zwiGy8"
      },
      "source": [
        "## CREATE THE API!!!\n",
        "\n",
        "At this stage we have a system that can create images given a written prompt. Let's use **Fast API** to create an API which given a query `prompt=\"A pug dressed like Napoleon` generates the image and returns it back.\n",
        "\n",
        "Example:\n",
        "\n",
        "`http://your-public-address.com?prompt=\"A pug dressed like Napoleon\"`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYkBusDsiw_D"
      },
      "source": [
        "1. Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAbslUIMiWix"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi nest-asyncio pyngrok uvicorn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBa-8wW2jDRc"
      },
      "source": [
        "2. Create the API definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gVWgfd3jV7J"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, Response\n",
        "import asyncio\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root(prompt: str):\n",
        "    return Response(content=dream(prompt), media_type=\"image/png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3pkBblklA29"
      },
      "source": [
        "3. Run the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jnhrbzi2lCAc"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}